--- /media/mks/5dcae443-0796-4029-ae6c-bf5bd2a37067/usr/bin/unattended-upgrade	2019-06-08 10:59:45.000000000 -0400
+++ /media/mks/armbi_root/usr/bin/unattended-upgrade	2022-12-31 15:59:00.000000000 -0500
@@ -50,15 +50,20 @@
 import syslog
 
 try:
-    from typing import AbstractSet, cast, Dict, Iterable, List, Tuple
+    from typing import AbstractSet, cast, DefaultDict, Dict, Iterable, List
     AbstractSet  # pyflakes
+    DefaultDict  # pyflakes
     Dict  # pyflakes
     Iterable  # pyflakes
     List  # pyflakes
+    from typing import Set, Tuple, Union
+    Set  # pyflakes
     Tuple  # pyflakes
+    Union  # pyflakes
 except ImportError:
     pass
 
+from collections import defaultdict, namedtuple
 from datetime import date
 from email.message import Message
 from gettext import gettext as _
@@ -72,6 +77,8 @@
     Popen,
     PIPE,
 )
+from textwrap import wrap
+
 import apt
 import apt_inst
 import apt_pkg
@@ -81,6 +88,7 @@
 
 # the reboot required flag file used by packages
 REBOOT_REQUIRED_FILE = "/var/run/reboot-required"
+KEPT_PACKAGES_FILE = "var/lib/unattended-upgrades/kept-back"
 MAIL_BINARY = "/usr/bin/mail"
 SENDMAIL_BINARY = "/usr/sbin/sendmail"
 USERS = "/usr/bin/users"
@@ -107,6 +115,8 @@
 # messages to be logged only once
 logged_msgs = set()  # type: AbstractSet[str]
 
+NEVER_PIN = -32768
+
 
 class LoggingDateTime:
     """The date/time representation for the dpkg log file timestamps"""
@@ -133,37 +143,194 @@
     pass
 
 
+PkgPin = namedtuple('PkgPin', ['pkg', 'priority'])
+PkgFilePin = namedtuple('PkgFilePin', ['id', 'priority'])
+
+
 class UnattendedUpgradesCache(apt.Cache):
 
-    def __init__(self, rootdir, allowed_origins):
-        # type: (str, List[str]) -> None
-        self._cached_candidate_pkgnames = set()  # type: AbstractSet[str]
-        self.allowed_origins = allowed_origins
+    def __init__(self, rootdir):
+        # type: (str) -> None
+        self._cached_candidate_pkgnames = set()  # type: Set[str]
+
+        self.allowed_origins = get_allowed_origins()
+        logging.info(_("Allowed origins are: %s"),
+                     ", ".join(self.allowed_origins))
+
+        self.blacklist = apt_pkg.config.value_list(
+            "Unattended-Upgrade::Package-Blacklist")
+        logging.info(_("Initial blacklist: %s"), " ".join(self.blacklist))
+
+        self.whitelist = apt_pkg.config.value_list(
+            "Unattended-Upgrade::Package-Whitelist")
+        self.strict_whitelist = apt_pkg.config.find_b(
+            "Unattended-Upgrade::Package-Whitelist-Strict", False)
+        logging.info(_("Initial whitelist (%s): %s"),
+                     "strict" if self.strict_whitelist else "not strict",
+                     " ".join(self.whitelist))
         apt.Cache.__init__(self, rootdir=rootdir)
 
         # pre-heat lazy-loaded modules to avoid crash on python upgrade
         datetime.datetime.strptime("", "")
 
         # generate versioned_kernel_pkgs_regexp for later use
-        apt_versioned_kernel_pkgs = apt_pkg.config.value_list(
-            "APT::VersionedKernelPackages")
-        if apt_versioned_kernel_pkgs:
-            self.versioned_kernel_pkgs_regexp = re.compile("(" + "|".join(
-                ["^" + p + "-[0-9]+\\.[0-9\\.]+-.*"
-                 for p in apt_versioned_kernel_pkgs]) + ")")
+        self.versioned_kernel_pkgs_regexp = versioned_kernel_pkgs_regexp()
+        self.running_kernel_pkgs_regexp = running_kernel_pkgs_regexp()
+        if self.versioned_kernel_pkgs_regexp:
             logging.debug("Using %s regexp to find kernel packages",
                           self.versioned_kernel_pkgs_regexp.pattern)
-            running_kernel_version = subprocess.check_output(
-                ["uname", "-r"], universal_newlines=True).rstrip()
-            self.running_kernel_pkgs_regexp = re.compile("(" + "|".join(
-                [("^" + p + "-" + re.escape(running_kernel_version) + "$")
-                 for p in apt_versioned_kernel_pkgs]) + ")")
-            logging.debug("Using %s regexp to find running kernel packages",
-                          self.running_kernel_pkgs_regexp.pattern)
         else:
             logging.debug("APT::VersionedKernelPackages is not set")
-            self.versioned_kernel_pkgs_regexp = None
-            self.running_kernel_pkgs_regexp = None
+        if self.running_kernel_pkgs_regexp:
+            logging.debug("Using %s regexp to find running kernel packages",
+                          self.running_kernel_pkgs_regexp.pattern)
+
+    def find_better_version(self, pkg):
+        # type (apt.Package) -> apt.package.Version
+        if pkg.is_installed and pkg.versions[0] > pkg.installed:
+            logging.debug(
+                "Package %s has a higher version available, checking if it is "
+                "from an allowed origin and is not pinned down.", pkg.name)
+            for v in pkg.versions:
+                if pkg.installed < v \
+                   and pkg.installed.policy_priority <= v.policy_priority \
+                   and is_in_allowed_origin(v, self.allowed_origins):
+                    return v
+        return None
+
+    def find_kept_packages(self, dry_run):
+        # type: (bool) -> KeptPkgs
+        """ Find kept packages not collected already """
+
+        kept_packages = KeptPkgs(set)
+        if dry_run:
+            logging.info(_("The list of kept packages can't be calculated in "
+                           "dry-run mode."))
+            return kept_packages
+        for pkg in self:
+            better_version = self.find_better_version(pkg)
+            if better_version:
+                logging.info(self.kept_package_excuse(pkg._pkg,
+                                                      self.blacklist,
+                                                      self.whitelist,
+                                                      self.strict_whitelist,
+                                                      better_version))
+                kept_packages.add(pkg, better_version, self)
+        return kept_packages
+
+    def kept_package_excuse(self, pkg,          # apt.Package
+                            blacklist,          # type: List[str]
+                            whitelist,          # type: List[str]
+                            strict_whitelist,   # type: bool
+                            better_version      # type: apt.package.Version
+                            ):
+        # type: (...) -> str
+        """ Log the excuse the package is kept back for """
+        if pkg.selected_state == apt_pkg.SELSTATE_HOLD:
+            return _("Package %s is marked to be held back.") % pkg.name
+        elif is_pkgname_in_blacklist(pkg.name, blacklist):
+            return _("Package %s is blacklisted.") % pkg.name
+        elif whitelist:
+            if strict_whitelist:
+                if not is_pkgname_in_whitelist(pkg.name, whitelist):
+                    return (_(
+                        "Package %s is not on the strict whitelist.")
+                            % pkg.name)
+                else:
+                    if not is_pkgname_in_whitelist(pkg.name, whitelist):
+                        return (_(
+                            "Package %s is not whitelisted and it is not a"
+                            " dependency of a whitelisted package.")
+                                % pkg.name)
+        elif not any([o.trusted for o in better_version.origins]):
+            return _("Package %s's origin is not trusted.") % pkg.name
+        return (_("Package %s is kept back because a related package"
+                  " is kept back or due to local apt_preferences(5).")
+                % pkg.name)
+
+    def pinning_from_regex_list(self, regexps, priority):
+        # type: (List[str], int) -> List[PkgPin]
+        """ Represent blacklist as Python regexps as list of pkg pinnings"""
+
+        pins = []  # type: List[PkgPin]
+        for regex in regexps:
+            if python_regex_is_posix(regex):
+                pins.append(PkgPin('/^' + regex + '/', priority))
+            else:
+                # Python regex is not also an equivalent POSIX regexp.
+                # This is expected to be rare. Go through all the package names
+                # and pin all the matching ones.
+                for pkg in self._cache.packages:
+                    if re.match(regex, pkg.name):
+                        pins.append(PkgPin(pkg.name, priority))
+        return pins
+
+    def pinning_from_config(self):
+        # type: () -> List[Union[PkgPin, PkgFilePin]]
+        """ Represent configuration as list of pinnings
+
+            Assumes self.allowed_origins to be already set.
+        """
+
+        pins = []  # type: List[Union[PkgPin, PkgFilePin]]
+
+        # mark not allowed origins with 'never' pin
+        for pkg_file in self._cache.file_list:  # type: ignore
+            if not is_allowed_origin(pkg_file, self.allowed_origins):
+                # Set the magic 'never' pin on not allowed origins
+                logging.debug("Marking not allowed %s with %s pin", pkg_file,
+                              NEVER_PIN)
+                pins.append(PkgFilePin(pkg_file.id, NEVER_PIN))
+            # TODO(rbalint) pin not trusted origins with NEVER_PIN
+            elif self.strict_whitelist:
+                # set even allowed origins to -1 and set individual package
+                # priorities up later
+                pins.append(PkgFilePin(pkg_file.id, -1))
+
+        # mark blacklisted packages with 'never' pin
+        pins.extend(self.pinning_from_regex_list(  # type: ignore
+            self.blacklist, NEVER_PIN))
+        # set priority of whitelisted packages to high
+        pins.extend(self.pinning_from_regex_list(  # type: ignore
+            self.whitelist, 900))
+        if self.strict_whitelist:
+            policy = self._depcache.policy
+            # pin down already pinned packages which are not on the whitelist
+            # to not install locally pinned up packages accidentally
+            for pkg in self._cache.packages:
+                if pkg.has_versions:
+                    pkg_ver = policy.get_candidate_ver(pkg)  # type: ignore
+                    if pkg_ver is not None \
+                       and policy.get_priority(pkg_ver) > -1:
+                        # the pin is higher than set for allowed origins, thus
+                        # there is extra pinning configuration
+                        if not is_pkgname_in_whitelist(pkg.name,
+                                                       self.whitelist):
+                            pins.append(PkgPin(pkg.name, NEVER_PIN))
+
+        return pins
+
+    def apply_pinning(self, pins):
+        # type: (List[Union[PkgPin, PkgFilePin]]) -> None
+        """ Apply the list of pins """
+
+        policy = self._depcache.policy
+        pkg_files = {f.id: f for f in self._cache.file_list}  # type: ignore
+        for pin in pins:
+            logging.debug("Applying pinning: %s" % str(pin))
+            if isinstance(pin, PkgPin):
+                policy.create_pin('Version', pin.pkg, '*',  # type: ignore
+                                  pin.priority)
+            elif isinstance(pin, PkgFilePin):
+                logging.debug("Applying pin %s to package_file: %s"
+                              % (pin.priority, str(pkg_files[pin.id])))
+                policy.set_priority(pkg_files[pin.id],  # type: ignore
+                                    pin.priority)
+
+    def open(self, progress=None):
+        apt.Cache.open(self, progress)
+        # apply pinning generated from unattended-upgrades configuration
+        self.apply_pinning(self.pinning_from_config())
 
     def adjust_candidate(self, pkg):
         # type: (apt.Package) -> bool
@@ -178,7 +345,7 @@
             # Only adjust to lower versions to avoid flipping back and forth
             # and to avoid picking a newer version, not selected by apt.
             # This helps avoiding upgrades to experimental's packages.
-            if new_cand.version < pkg.candidate.version:
+            if pkg.candidate is not None and new_cand < pkg.candidate:
                 logging.debug("adjusting candidate version: %s" % new_cand)
                 pkg.candidate = new_cand
                 return True
@@ -187,6 +354,22 @@
         except NoAllowedOriginError:
             return False
 
+    def call_checked(self, function, pkg, **kwargs):
+        """ Call function and check if package is in the wanted state
+        """
+        try:
+            function(pkg, **kwargs)
+        except SystemError as e:
+            logging.warning(
+                _("package %s upgradable but fails to "
+                  "be marked for upgrade (%s)"), pkg.name, e)
+            self.clear()
+            return False
+
+        return ((function == apt.package.Package.mark_upgrade
+                 or function == apt.package.Package.mark_install)
+                and (pkg.marked_upgrade or pkg.marked_install))
+
     def call_adjusted(self, function, pkg, **kwargs):
         """Call function, but with adjusting
            packages in changes to come from allowed origins
@@ -195,31 +378,55 @@
            adjusted than only the one's in the final changes set.
         """
         new_pkgs_to_adjust = []  # List[str]
-        pkgs_with_no_allowed_origin = []
 
-        # adjust candidates in advance if needed
-        for pkg_name in self._cached_candidate_pkgnames:
-            self.adjust_candidate(self[pkg_name])
+        if not is_pkg_change_allowed(pkg, self.blacklist, self.whitelist,
+                                     self.strict_whitelist):
+            return
 
         if function == apt.package.Package.mark_upgrade \
-           and not pkg.is_upgradable:
-            raise NoAllowedOriginError
-        function(pkg, **kwargs)
-        changes = self.get_changes()
-        for marked_pkg in changes:
+                and not pkg.is_upgradable:
+            if not apt_pkg.config.find_b("Unattended-Upgrade::Allow-downgrade",
+                                         False):
+                return
+            else:
+                function = apt.package.Package.mark_install
+        marking_succeeded = self.call_checked(function, pkg, **kwargs)
+
+        if (not marking_succeeded
+            or not check_changes_for_sanity(self, desired_pkg=pkg)) \
+                and allow_marking_fallback():
+            logging.debug("falling back to adjusting %s's dependencies"
+                          % pkg.name)
+            self.clear()
+            # adjust candidates in advance if needed
+            for pkg_name in self._cached_candidate_pkgnames:
+                self.adjust_candidate(self[pkg_name])
+
+            self.adjust_candidate(pkg)
+            for dep in transitive_dependencies(pkg, self, level=1):
+                try:
+                    self.adjust_candidate(self[dep])
+                except KeyError:
+                    pass
+
+            self.call_checked(function, pkg, **kwargs)
+
+        for marked_pkg in self.get_changes():
             if marked_pkg.name in self._cached_candidate_pkgnames:
                 continue
-            if not is_allowed_origin(marked_pkg.candidate,
-                                     self.allowed_origins):
+            if not is_in_allowed_origin(marked_pkg.candidate,
+                                        self.allowed_origins):
                 try:
                     ver_in_allowed_origin(marked_pkg,
                                           self.allowed_origins)
                     # important! this avoids downgrades below
-                    if pkg.is_installed and not pkg.is_upgradable:
+                    if pkg.is_installed and not pkg.is_upgradable and \
+                            apt_pkg.config.find_b("Unattended-Upgrade::Allow-"
+                                                  "downgrade", False):
                         continue
                     new_pkgs_to_adjust.append(marked_pkg)
                 except NoAllowedOriginError:
-                    pkgs_with_no_allowed_origin.append(marked_pkg)
+                    pass
 
         if new_pkgs_to_adjust:
             new_pkg_adjusted = False
@@ -229,9 +436,6 @@
                     new_pkg_adjusted = True
             if new_pkg_adjusted:
                 self.call_adjusted(function, pkg, **kwargs)
-        else:
-            if pkgs_with_no_allowed_origin:
-                raise NoAllowedOriginError
 
     def mark_upgrade_adjusted(self, pkg, **kwargs):
         self.call_adjusted(apt.package.Package.mark_upgrade, pkg, **kwargs)
@@ -377,21 +581,31 @@
         # type: () -> None
         try:
             apt_pkg.pkgsystem_unlock_inner()
-        except AttributeError:
-            try:
-                apt_pkg.pkgsystem_unlock()
-            except Exception:
-                # earlier python-apt used to leak lock
-                logging.warning("apt_pkg.pkgsystem_unlock() failed due to not "
-                                "holding the lock but trying to continue")
-                pass
+        except Exception:
+            # earlier python-apt used to leak lock
+            logging.warning("apt_pkg.pkgsystem_unlock() failed due to not "
+                            "holding the lock but trying to continue")
+            pass
 
     def __exit__(self, exc_type, exc_value, exc_tb):
         # type: (object, object, object) -> None
-        try:
-            apt_pkg.pkgsystem_lock_inner()
-        except AttributeError:
-            apt_pkg.pkgsystem_lock()
+        apt_pkg.pkgsystem_lock_inner()
+
+
+class KeptPkgs(defaultdict):
+    """
+    Packages to keep by highest allowed pretty-printed origin
+
+    """
+    def add(self, pkg,  # type: apt.Package
+            version,    # type: apt.package.Version
+            cache       # type: UnattendedUpgradesCache
+            ):
+        # type: (...) -> None
+        for origin in version.origins:
+            if is_allowed_origin(origin, cache.allowed_origins):
+                self[origin.origin + " " + origin.archive].add(pkg.name)
+                return
 
 
 class UnattendedUpgradesResult:
@@ -403,7 +617,7 @@
                  success,                 # type: bool
                  result_str="",           # type: str
                  pkgs=[],                 # type: List[str]
-                 pkgs_kept_back=[],       # type: List[str]
+                 pkgs_kept_back=KeptPkgs(set),     # type: KeptPkgs
                  pkgs_removed=[],         # type: List[str]
                  pkgs_kept_installed=[],  # type: List[str]
                  update_stamp=False       # type: bool
@@ -441,7 +655,7 @@
 
 
 def log_once(msg):
-    #type: (str) -> None
+    # type: (str) -> None
     global logged_msgs
     if msg not in logged_msgs:
         logging.info(msg)
@@ -502,6 +716,48 @@
     return DISTRO_ID
 
 
+def allow_marking_fallback():
+    # type: () -> bool
+    return apt_pkg.config.find_b(
+        "Unattended-Upgrade::Allow-APT-Mark-Fallback",
+        get_distro_codename() != "sid")
+
+
+def versioned_kernel_pkgs_regexp():
+    apt_versioned_kernel_pkgs = apt_pkg.config.value_list(
+        "APT::VersionedKernelPackages")
+    if apt_versioned_kernel_pkgs:
+        return re.compile("(" + "|".join(
+            ["^" + p + "-[1-9][0-9]*\\.[0-9]+\\.[0-9]+-[0-9]+(-.+)?$"
+             for p in apt_versioned_kernel_pkgs]) + ")")
+    else:
+        return None
+
+
+def running_kernel_pkgs_regexp():
+    apt_versioned_kernel_pkgs = apt_pkg.config.value_list(
+        "APT::VersionedKernelPackages")
+    if apt_versioned_kernel_pkgs:
+        running_kernel_version = subprocess.check_output(
+            ["uname", "-r"], universal_newlines=True).rstrip()
+        kernel_escaped = re.escape(running_kernel_version)
+        try:
+            kernel_noflavor_escaped = re.escape(
+                re.match("[1-9][0-9]*\\.[0-9]+\\.[0-9]+-[0-9]+",
+                         running_kernel_version)[0])
+            return re.compile("(" + "|".join(
+                [("^" + p + "-" + kernel_escaped + "$|^"
+                  + p + "-" + kernel_noflavor_escaped + "$")
+                 for p in apt_versioned_kernel_pkgs]) + ")")
+        except TypeError:
+            # flavor could not be cut from version
+            return re.compile("(" + "|".join(
+                [("^" + p + "-" + kernel_escaped + "$")
+                 for p in apt_versioned_kernel_pkgs]) + ")")
+    else:
+        return None
+
+
 def get_allowed_origins_legacy():
     # type: () -> List[str]
     """ legacy support for old Allowed-Origins var """
@@ -546,7 +802,7 @@
 
 
 def match_whitelist_string(whitelist, origin):
-    # type: (str, apt.package.Origin) -> bool
+    # type: (str, Union[apt.package.Origin, apt_pkg.PackageFile]) -> bool
     """
     take a whitelist string in the form "origin=Debian,label=Debian-Security"
     and match against the given python-apt origin. A empty whitelist string
@@ -592,6 +848,12 @@
     return res
 
 
+def python_regex_is_posix(expression):
+    # type: (str) -> bool
+    """ Returns if the Python regex is also an equivalent POSIX regex """
+    return re.match("^[-a-zA-Z0-9\\^\\$\\+\\.:]*$", expression) is not None
+
+
 def cache_commit(cache,           # type: apt.Cache
                  logfile_dpkg,    # type: str
                  verbose,         # type: bool
@@ -606,11 +868,7 @@
         iprogress = LogInstallProgress(logfile_dpkg, verbose)
 
     try:
-        if hasattr(apt_pkg, "pkgsystem_lock_inner"):
-            res = cache.commit(install_progress=iprogress)
-        else:
-            with Unlocked():
-                res = cache.commit(install_progress=iprogress)
+        res = cache.commit(install_progress=iprogress)
         cache.open()
     except SystemError as e:
         error = e
@@ -633,18 +891,15 @@
     return res
 
 
-def upgrade_in_minimal_steps(cache,            # type: apt.Cache
+def upgrade_in_minimal_steps(cache,            # type: UnattendedUpgradesCache
                              pkgs_to_upgrade,  # type: List[str]
-                             blacklist,        # type: List[str]
-                             whitelist,        # type: List[str]
                              logfile_dpkg="",  # type: str
                              verbose=False,    # type: bool
                              ):
     # type: (...) -> bool
     install_log = LogInstallProgress(logfile_dpkg, verbose)
 
-    # double check any changes we do
-    allowed_origins = get_allowed_origins()
+    res = True
 
     # to upgrade contains the package names
     to_upgrade = set(pkgs_to_upgrade)
@@ -657,17 +912,26 @@
         if should_stop():
             return False
         pkg = cache[pkgname]
-        if pkg.is_upgradable:
-            cache.mark_upgrade_adjusted(pkg,
-                                        from_user=not pkg.is_auto_installed)
-        elif not pkg.is_installed:
-            cache.mark_install_adjusted(pkg, from_user=False)
-        else:
+        try:
+            if pkg.is_upgradable \
+               or candidate_version_changed(pkg):
+                cache.mark_upgrade_adjusted(
+                    pkg, from_user=not pkg.is_auto_installed)
+            elif not pkg.is_installed:
+                cache.mark_install_adjusted(pkg, from_user=False)
+            else:
+                continue
+        except Exception as e:
+            logging.warning(
+                _("package %s upgradable but fails to "
+                  "be marked for upgrade (%s)"), pkgname, e)
+            cache.clear()
+            res = False
             continue
+
         # double check that we are not running into side effects like
         # what could have been caused LP: #1020680
-        if not check_changes_for_sanity(cache, allowed_origins, blacklist,
-                                        whitelist):
+        if not check_changes_for_sanity(cache):
             logging.info("While building minimal partition: "
                          "cache has not allowed changes")
             cache.clear()
@@ -703,32 +967,36 @@
         if len(to_upgrade) == 0:
             logging.info(_("All upgrades installed"))
             break
-    return True
+    return res
+
+
+def is_allowed_origin(origin, allowed_origins):
+    # type: (Union[apt.package.Origin, apt_pkg.PackageFile], List[str]) -> bool
+
+    # local origin is allowed by default
+    if origin.component == 'now' and origin.archive == 'now' and \
+       not origin.label and not origin.site:
+        return True
+    for allowed in allowed_origins:
+        if match_whitelist_string(allowed, origin):
+            return True
+    return False
 
 
-def is_allowed_origin(ver, allowed_origins):
+def is_in_allowed_origin(ver, allowed_origins):
     # type: (apt.package.Version, List[str]) -> bool
     if not ver:
         return False
     for origin in ver.origins:
-        for allowed in allowed_origins:
-            if match_whitelist_string(allowed, origin):
-                return True
+        if is_allowed_origin(origin, allowed_origins):
+            return True
     return False
 
 
 def ver_in_allowed_origin(pkg, allowed_origins):
     # type: (apt.Package, List[str]) -> apt.package.Version
     for ver in pkg.versions:
-        # ignore versions that the user marked with priority < 100
-        # (and ensure we have a python-apt that supports this)
-        try:
-            if ver.policy_priority < 100:
-                logging.debug("ignoring ver %s with priority < 0" % ver)
-                continue
-        except AttributeError:
-            pass
-        if is_allowed_origin(ver, allowed_origins):
+        if is_in_allowed_origin(ver, allowed_origins):
             # leave as soon as we have the highest new candidate
             return ver
     raise NoAllowedOriginError()
@@ -756,8 +1024,8 @@
     return False
 
 
-def is_pkg_change_allowed(pkg, blacklist, whitelist):
-    # type: (apt.Package, List[str], List[str]) -> bool
+def is_pkg_change_allowed(pkg, blacklist, whitelist, strict_whitelist):
+    # type: (apt.Package, List[str], List[str], bool) -> bool
     if is_pkgname_in_blacklist(pkg.name, blacklist):
         logging.debug("pkg %s package has been blacklisted" % pkg.name)
         return False
@@ -765,8 +1033,6 @@
     # whitelist, most people will want the relaxed whitelist
     # that whitelists a package but pulls in the package
     # dependencies
-    strict_whitelist = apt_pkg.config.find_b(
-        "Unattended-Upgrade::Package-Whitelist-Strict", False)
     if strict_whitelist and \
        not is_pkgname_in_whitelist(pkg.name, whitelist):
 
@@ -779,20 +1045,31 @@
     return True
 
 
-def transitive_dependencies(pkg, cache, acc=set()):
-    # type (apt.Package, apt.Cache, AbstractSet[str]) -> bool
+def transitive_dependencies(pkg,               # type: apt.Package
+                            cache,             # type: apt.Cache
+                            acc=set(),         # type AbstractSet[str]
+                            valid_types=None,  # type: AbstractSet[str]
+                            level=None         # type: int
+                            ):
+    # type (...) -> AbstractSet[str]
     """ All (transitive) dependencies of the package
+
+        Note that alternative (|) dependencies are collected, too
     """
-    # Note that alternative (|) dependencies are collected, too
-    valid_types = {'Depends', 'PreDepends', 'Recommends'}
+    if not pkg.candidate or level is not None and level < 1:
+        return acc
+
     for dep in pkg.candidate.dependencies:
         for base_dep in dep:
-            if base_dep.name not in acc and base_dep.rawtype in valid_types:
-                acc.add(base_dep.name)
-                try:
-                    transitive_dependencies(cache[base_dep.name], cache, acc)
-                except KeyError:
-                    pass
+            if base_dep.name not in acc:
+                if not valid_types or base_dep.rawtype in valid_types:
+                    acc.add(base_dep.name)
+                    try:
+                        transitive_dependencies(
+                            cache[base_dep.name], cache, acc, valid_types,
+                            level=(level - 1 if level is not None else None))
+                    except KeyError:
+                        pass
     return acc
 
 
@@ -804,50 +1081,63 @@
 
     upgrade_set_sizes = {}
     # calculate upgrade sets
+    follow_deps = {'Depends', 'PreDepends', 'Recommends'}
     for pkgname in to_upgrade:
         pkg = cache[pkgname]
-        upgrade_set_sizes[pkgname] = \
-            len(transitive_dependencies(pkg, cache).intersection(to_upgrade))
+        upgrade_set_sizes[pkgname] = len(transitive_dependencies(
+            pkg, cache, valid_types=follow_deps).intersection(to_upgrade))
     return sorted(upgrade_set_sizes, key=upgrade_set_sizes.get)
 
 
-def check_changes_for_sanity(cache, allowed_origins, blacklist, whitelist,
-                             desired_pkg=None):
-    # type: (apt.Cache, List[str], List[str], List[str], apt.Package) -> bool
-    if cache._depcache.broken_count != 0:
+def check_changes_for_sanity(cache, desired_pkg=None):
+    # type: (UnattendedUpgradesCache, apt.Package) -> bool
+    sanity_check_result = sanity_problem(cache, desired_pkg)
+    if sanity_check_result is None:
+        return True
+    else:
+        logging.debug("sanity check failed for: %s : %s"
+                      % (str({str(p.candidate) for p in cache.get_changes()}),
+                         sanity_check_result))
         return False
+
+
+def sanity_problem(cache, desired_pkg):
+    # type: (UnattendedUpgradesCache, apt.Package) -> str
+    if cache._depcache.broken_count != 0:
+        return ("there are broken packages in the cache")
     # If there are no packages to be installed they were kept back
     if cache.install_count == 0:
-        return False
+        return ("no package is selected to be upgraded or installed")
     changes = cache.get_changes()
     for pkg in changes:
         if pkg.marked_delete:
-            logging.debug("pkg %s now marked delete" % pkg.name)
-            return False
+            return ("pkg %s is marked to be deleted" % pkg.name)
         if pkg.marked_install or pkg.marked_upgrade:
             # apt will never fallback from a trusted to a untrusted
             # origin so its good enough if we have a single trusted one
             if not any([o.trusted for o in pkg.candidate.origins]):
-                logging.debug("pkg %s is untrusted" % pkg.name)
-                return False
-            if not is_allowed_origin(pkg.candidate, allowed_origins):
-                logging.debug("pkg %s not in allowed origin" % pkg.name)
-                return False
-            if not is_pkg_change_allowed(pkg, blacklist, whitelist):
-                return False
+                return ("pkg %s is not from a trusted origin" % pkg.name)
+            if not is_in_allowed_origin(pkg.candidate, cache.allowed_origins):
+                return ("pkg %s is not in an allowed origin" % pkg.name)
+            if not is_pkg_change_allowed(pkg,
+                                         cache.blacklist,
+                                         cache.whitelist,
+                                         cache.strict_whitelist):
+                return ("pkg %s is blacklisted or is not whitelisted"
+                        % pkg.name)
             # check if the package is unsafe to upgrade unattended
             ignore_require_restart = apt_pkg.config.find_b(
                 "Unattended-Upgrade::IgnoreAppsRequireRestart", False)
             upgrade_requires = pkg.candidate.record.get("Upgrade-Requires")
             if pkg.marked_upgrade and ignore_require_restart is False \
                and upgrade_requires == "app-restart":
-                logging.debug("pkg %s requires app-restart, not safe to "
-                              "upgrade unattended")
-                return False
+                return ("pkg %s requires app-restart, it is not safe to "
+                        "upgrade it unattended")
     # check that the package we want to upgrade is in the change set
     if desired_pkg and desired_pkg not in changes:
-        return False
-    return True
+        return ("pkg %s to be marked for upgrade/install is not marked "
+                "accordingly" % desired_pkg.name)
+    return None
 
 
 def is_deb(file):
@@ -882,12 +1172,55 @@
     md5_p = Popen(md5_cmd, stdin=tar_p.stdout, stdout=PIPE,
                   universal_newlines=True)
     pkg_md5sum = md5_p.communicate()[0].split()[0]
-    for p in [dpkg_p, tar_p, md5_p]:
+    for __p in [dpkg_p, tar_p, md5_p]:
+        p = cast(Popen, __p)
         p.stdout.close()
         p.wait()
     return pkg_md5sum
 
 
+def get_md5sum_for_file_installed(conf_file, prefix):
+    # type: (str, str) -> str
+    try:
+        with open(prefix + conf_file, 'rb') as fb:
+            for hash_string in apt_pkg.Hashes(fb).hashes:  # type: ignore
+                if hash_string.hashtype == 'MD5Sum':
+                    return hash_string.hashvalue
+            return None
+    except IsADirectoryError:
+        # the package replaces a directory wih a configuration file
+        #
+        # if the package changed this way it is safe to assume that
+        # the transition happens without showing a prompt but if the admin
+        # created the directory the admin will need to resolve it after
+        # being notified about the unexpected prompt
+        logging.debug("found conffile %s is a directory on the system "
+                      % conf_file)
+        return "dir"
+    except FileNotFoundError:
+        # if the local file got deleted by the admin thats ok but it may still
+        # trigger a conffile promp (see debian #788049)
+        logging.debug("conffile %s in missing on the system" % conf_file)
+        return ""
+
+
+def map_conf_file(conf_file, conffiles):
+    # type: (str, Union[AbstractSet[str], Dict[str, str]]) -> str
+    """Find respective conffile in a set of conffiles with some heuristics
+    """
+    if conf_file in conffiles:
+        return conf_file
+    elif os.path.join(conf_file, os.path.basename(conf_file)) in conffiles:
+        # new /etc/foo may be old /etc/foo/foo, like in LP: #1822745
+        return os.path.join(conf_file, os.path.basename(conf_file))
+    elif os.path.dirname(conf_file) in conffiles:
+        # new /etc/foo/foo may be old /etc/foo, probably by accident
+        return os.path.dirname(conf_file)
+    # TODO: peek into package's dpkg-maintscript-helper mv_conffile usage
+    else:
+        return None
+
+
 # prefix is *only* needed for the build-in tests
 def conffile_prompt(destFile, prefix=""):
     # type: (str, str) -> bool
@@ -908,11 +1241,11 @@
 
     # get conffile value from pkg, its ok if the new version
     # does not have conffiles anymore
-    pkg_conffiles = ""
+    pkg_conffiles = set()  # type: AbstractSet[str]
     try:
         deb = apt_inst.DebFile(destFile)
-        pkg_conffiles = deb.control.extractdata("conffiles").strip().decode(
-            "utf-8")
+        pkg_conffiles = set(deb.control.extractdata(
+            "conffiles").strip().decode("utf-8").split("\n"))
     except SystemError as e:
         print(_("Apt returned an error, exiting"))
         print(_("error message: %s") % e)
@@ -921,6 +1254,8 @@
         raise
     except LookupError as e:
         logging.debug("No conffiles in deb %s (%s)" % (destFile, e))
+    if not pkg_conffiles:
+        return False
 
     # Conffiles:
     #  /etc/bash_completion.d/m-a c7780fab6b14d75ca54e11e992a6c11c
@@ -946,36 +1281,25 @@
         # might be a dpkg prompt (LP: #936870)
         if md5 == "newconffile":
             continue
-        if not pkg_conffiles or conf_file not in pkg_conffiles.split("\n"):
+        new_conf_file = map_conf_file(conf_file, pkg_conffiles)
+        if not new_conf_file:
             logging.debug("%s not in package conffiles %s" % (
                 conf_file, pkg_conffiles))
             continue
         # record for later
         dpkg_status_conffiles[conf_file] = md5
 
-        # the package replaces a directory wih a configuration file
-        #
-        # if the package changed this way it is safe to assume that
-        # the transition happens without showing a prompt but if the admin
-        # created the directory the admin will need to resolve it after
-        # being notified about the unexpected prompt
-        if os.path.isdir(prefix + conf_file):
-            continue
-
         # test against the installed file, if the local file got deleted
         # by the admin thats ok but it may still trigger a conffile prompt
         # (see debian #788049)
-        current_md5 = ""
-        if os.path.exists(prefix + conf_file):
-            with open(prefix + conf_file, 'rb') as fb:
-                current_md5 = apt_pkg.md5sum(fb)
+        current_md5 = get_md5sum_for_file_installed(conf_file, prefix)
         logging.debug("current md5: %s" % current_md5)
 
         # hashes are the same, no conffile prompt
         if current_md5 == md5:
             continue
         # calculate md5sum from the deb (may take a bit)
-        pkg_md5sum = get_md5sum_for_file_in_deb(destFile, conf_file)
+        pkg_md5sum = get_md5sum_for_file_in_deb(destFile, new_conf_file)
         logging.debug("pkg_md5sum: %s" % pkg_md5sum)
         # the md5sum in the deb is unchanged, this will not
         # trigger a conffile prompt
@@ -990,15 +1314,13 @@
     # now check if there are conffiles in the pkg that where not there
     # in the previous version in the dpkg status file
     if pkg_conffiles:
-        for conf_file in pkg_conffiles.split("\n"):
-            if conf_file not in dpkg_status_conffiles \
-               and os.path.exists(prefix + conf_file):
-                logging.debug("found conffile %s in new pkg but on dpkg "
-                              "status" % conf_file)
+        for conf_file in pkg_conffiles:
+            old_conf_file = map_conf_file(conf_file, dpkg_status_conffiles)
+            if not old_conf_file:
                 pkg_md5sum = get_md5sum_for_file_in_deb(destFile, conf_file)
-                with open(prefix + conf_file, 'rb') as fp:
-                    if pkg_md5sum != apt_pkg.md5sum(fp):
-                        return True
+                current_md5 = get_md5sum_for_file_installed(conf_file, prefix)
+                if current_md5 != "" and pkg_md5sum != current_md5:
+                    return True
     return False
 
 
@@ -1015,11 +1337,11 @@
 
 
 def rewind_cache(cache, pkgs_to_upgrade):
-    # type: (apt.Cache, List[apt.Package]) -> None
+    # type: (UnattendedUpgradesCache, List[apt.Package]) -> None
     """ set the cache back to the state with packages_to_upgrade """
     cache.clear()
     for pkg2 in pkgs_to_upgrade:
-        pkg2.mark_install(from_user=not pkg2.is_auto_installed)
+        cache.mark_install_adjusted(pkg2, from_user=not pkg2.is_auto_installed)
     if cache.broken_count > 0:
         raise AssertionError("rewind_cache created a broken cache")
 
@@ -1029,16 +1351,10 @@
     return socket.getfqdn()
 
 
-# *sigh* textwrap is nice, but it breaks "linux-image" into two
-# seperate lines
-def wrap(t, width=70, subsequent_indent=""):
-    # type: (str, int, str) -> str
-    out = ""
-    for s in t.split():
-        if (len(out) - out.rfind("\n")) + len(s) > width:
-            out += "\n" + subsequent_indent
-        out += s + " "
-    return out
+def wrap_indent(t, subsequent_indent=" "):
+    # type: (str, str) -> str
+    return "\n".join(wrap(t, break_on_hyphens=False,
+                          subsequent_indent=subsequent_indent))
 
 
 def setup_apt_listchanges(conf="/etc/apt/listchanges.conf"):
@@ -1098,7 +1414,7 @@
 def send_summary_mail(pkgs,                 # type: List[str]
                       res,                  # type: bool
                       result_str,           # type: str
-                      pkgs_kept_back,       # type: List[str]
+                      pkgs_kept_back,       # type: KeptPkgs
                       pkgs_removed,         # type: List[str]
                       pkgs_kept_installed,  # type: List[str]
                       mem_log,              # type: StringIO
@@ -1110,18 +1426,36 @@
     if not to_email:
         return
     if not os.path.exists(MAIL_BINARY) and not os.path.exists(SENDMAIL_BINARY):
-        logging.error(_("No /usr/bin/mail or /usr/sbin/sendmail,"
+        logging.error(_("No /usr/bin/mail or /usr/sbin/sendmail, "
                         "can not send mail. "
                         "You probably want to install the mailx package."))
         return
+
+    # The admin may well wish to get a mail report regardless of what was done.
+    # This is now set by Unattended-Upgrade::MailReport values of:
+    #       "always", "only-on-error" or "on-change"
+    # (you can achieve "never" by not setting Unattended-Upgrade::Mail).
+    # If this is not set, then set it using any legacy MailOnlyOnError
+    # setting (default True)
+    #
+    mail_opt = apt_pkg.config.find("Unattended-Upgrade::MailReport")
+    if (mail_opt == ""):    # None set - map from legacy value
+        if apt_pkg.config.find_b("Unattended-Upgrade::MailOnlyOnError", False):
+            mail_opt = "only-on-error"
+        else:
+            mail_opt = "on-change"
+
     # if the operation was successful and the user has requested to get
-    # mails on on errors, just exit here
-    if (res and apt_pkg.config.find_b(
-            "Unattended-Upgrade::MailOnlyOnError", False)):
+    # mails only on errors, just exit here
+    if (res and (mail_opt == "only-on-error")):
         return
+
     # if the run was successful but nothing had to be done skip sending email
-    if (res and not pkgs and not pkgs_kept_back and not pkgs_removed):
+    # unless the admin wants it anyway
+    if (((mail_opt != "always") and res and not pkgs and not pkgs_kept_back
+         and not pkgs_removed)):
         return
+
     # Check if reboot-required flag is present
     reboot_flag_str = _(
         "[reboot required]") if os.path.isfile(REBOOT_REQUIRED_FILE) else ""
@@ -1134,7 +1468,7 @@
         "{machine}: {result}").format(
             hold_flag=hold_flag_str, reboot_flag=reboot_flag_str,
             machine=host(), result="SUCCESS" if res else "FAILURE").strip()
-    body = wrap(_("Unattended upgrade result: %s") % result_str, 70, " ")
+    body = wrap_indent(_("Unattended upgrade result: %s") % result_str)
     body += "\n\n"
     if os.path.isfile(REBOOT_REQUIRED_FILE):
         body += _(
@@ -1145,19 +1479,22 @@
             body += _("Packages that were upgraded:\n")
         else:
             body += _("Packages that attempted to upgrade:\n")
-        body += " " + wrap(" ".join(pkgs), 70, " ")
+        body += " " + wrap_indent(" ".join(pkgs))
         body += "\n\n"
     if pkgs_kept_back:
         body += _("Packages with upgradable origin but kept back:\n")
-        body += " " + wrap(" ".join(pkgs_kept_back), 70, " ")
-        body += "\n\n"
+        for origin, origin_pkgs in pkgs_kept_back.items():
+            body += " " + origin + ":\n"
+            body += "  " + wrap_indent(" ".join(origin_pkgs),
+                                       subsequent_indent="  ") + "\n"
+        body += "\n"
     if pkgs_removed:
         body += _("Packages that were auto-removed:\n")
-        body += " " + wrap(" ".join(pkgs_removed), 70, " ")
+        body += " " + wrap_indent(" ".join(pkgs_removed))
         body += "\n\n"
     if pkgs_kept_installed:
         body += _("Packages that were kept from being auto-removed:\n")
-        body += " " + wrap(" ".join(pkgs_kept_installed), 70, " ")
+        body += " " + wrap_indent(" ".join(pkgs_kept_installed))
         body += "\n\n"
     if dpkg_log_content:
         body += _("Package installation log:") + "\n"
@@ -1174,15 +1511,14 @@
         ret = _send_mail_using_mailx(from_email, to_email, subject, body)
     else:
         raise AssertionError(
-            "This should never be reached, if we are here we either "
-            "have sendmail or mailx. Please report this as a bug.")
+            "This should never be reached as we previously validated that we "
+            "either have sendmail or mailx. Maybe they've been removed in "
+            "this right moment?")
     logging.debug("mail returned: %s", ret)
 
 
-def do_install(cache,             # type: apt.Cache
-               pkgs_to_upgrade,   # type: List[apt.Package]
-               blacklist,         # type: List[str]
-               whitelist,         # type: List[str]
+def do_install(cache,             # type: UnattendedUpgradesCache
+               pkgs_to_upgrade,   # type: List[str]
                options,           # type: Options
                logfile_dpkg,      # type: str
                ):
@@ -1192,19 +1528,16 @@
 
     logging.info(_("Writing dpkg log to %s"), logfile_dpkg)
 
-    marked_delete = [pkg for pkg in cache.get_changes() if pkg.marked_delete]
-    if marked_delete:
-        raise AssertionError(
-            "Internal error. The following packages are marked for "
-            "removal:%s" % " ".join([pkg.name for pkg in marked_delete]))
+    if cache.get_changes():
+        cache.clear()
 
     pkg_install_success = False
     try:
         if options.minimal_upgrade_steps:
             # try upgrade all "pkgs" in minimal steps
             pkg_install_success = upgrade_in_minimal_steps(
-                cache, [pkg.name for pkg in pkgs_to_upgrade],
-                blacklist, whitelist, logfile_dpkg,
+                cache, pkgs_to_upgrade,
+                logfile_dpkg,
                 options.verbose or options.debug)
         else:
             mark_pkgs_to_upgrade(cache, pkgs_to_upgrade)
@@ -1294,7 +1627,7 @@
             "daemon")
         syslogHandler = logging.handlers.SysLogHandler(
             address='/dev/log',
-            facility=syslogFacility)
+            facility=syslogFacility)  # type: ignore
         syslogHandler.setFormatter(
             logging.Formatter("unattended-upgrade: %(message)s"))
         known = syslogHandler.facility_names.keys()  # type: ignore
@@ -1308,16 +1641,6 @@
     return mem_log
 
 
-def get_blacklist():
-    # type: () -> List[str]
-    return apt_pkg.config.value_list("Unattended-Upgrade::Package-Blacklist")
-
-
-def get_whitelist():
-    # type: () -> List[str]
-    return apt_pkg.config.value_list("Unattended-Upgrade::Package-Whitelist")
-
-
 def logged_in_users():
     # type: () -> AbstractSet[str]
     """Return a list of logged in users"""
@@ -1373,11 +1696,7 @@
 
 def try_to_upgrade(pkg,               # type: apt.Package
                    pkgs_to_upgrade,   # type: List[apt.Package]
-                   pkgs_kept_back,    # type: List[str]
-                   cache,             # type: apt.Cache
-                   allowed_origins,   # type: List[str]
-                   blacklist,         # type: List[str]
-                   whitelist,         # type: List[str]
+                   cache,             # type: UnattendedUpgradesCache
                    ):
     # type: (...) -> None
     try:
@@ -1385,72 +1704,61 @@
             # try to adjust pkg itself first, if that throws an exception it
             # can't be upgraded on its own
             cache.adjust_candidate(pkg)
-            if not pkg.is_upgradable:
+            if not pkg.is_upgradable and not apt_pkg.config.find_b(
+                    "Unattended-Upgrade::Allow-downgrade", False):
                 return
         except NoAllowedOriginError:
             return
         cache._cached_candidate_pkgnames.add(pkg.name)
         cache.mark_upgrade_adjusted(pkg, from_user=not pkg.is_auto_installed)
-        if check_changes_for_sanity(cache, allowed_origins, blacklist,
-                                    whitelist, pkg):
+        if check_changes_for_sanity(cache, pkg):
             # add to packages to upgrade
             pkgs_to_upgrade.append(pkg)
-            # re-eval pkgs_kept_back as the resolver may fail to
-            # directly upgrade a pkg, but that may work during
-            # a subsequent operation, see debian bug #639840
-            for pkgname in pkgs_kept_back:
-                if cache[pkgname].marked_install \
-                   or cache[pkgname].marked_upgrade:
-                    pkgs_kept_back.remove(pkgname)
-                    pkgs_to_upgrade.append(cache[pkgname])
         else:
-            logging.debug("sanity check failed")
             rewind_cache(cache, pkgs_to_upgrade)
-            pkgs_kept_back.append(pkg.name)
     except (SystemError, NoAllowedOriginError) as e:
         # can't upgrade
         logging.warning(
             _("package %s upgradable but fails to "
                 "be marked for upgrade (%s)"), pkg.name, e)
         rewind_cache(cache, pkgs_to_upgrade)
-        pkgs_kept_back.append(pkg.name)
 
 
-def calculate_upgradable_pkgs(cache,             # type: apt.Cache
-                              options,           # type: Options
-                              allowed_origins,   # type: List[str]
-                              blacklist,         # type: List[str]
-                              whitelist,         # type: List[str]
+def candidate_version_changed(pkg,               # type: apt.Package
+                              ):
+    return (pkg.is_installed and pkg.candidate
+            and pkg.candidate.version != pkg.installed.version
+            and apt_pkg.config.find_b(
+                'Unattended-Upgrade::Allow-downgrade', False))
+
+
+def calculate_upgradable_pkgs(cache,            # type: UnattendedUpgradesCache
+                              options,          # type: Options
                               ):
-    # type: (...) -> Tuple[List[apt.Package], List[str]]
+    # type: (...) -> List[apt.Package]
     pkgs_to_upgrade = []  # type: List[apt.Package]
-    pkgs_kept_back = []   # type: List[str]
 
     # now do the actual upgrade
     for pkg in cache:
-        if options.debug and pkg.is_upgradable:
+        if options.debug and pkg.is_upgradable \
+           or candidate_version_changed(pkg):
             logging.debug("Checking: %s (%s)" % (
                 pkg.name, getattr(pkg.candidate, "origins", [])))
 
-        if (pkg.is_upgradable
-                and is_pkgname_in_whitelist(pkg.name, whitelist)):
+        if (pkg.is_upgradable or candidate_version_changed(pkg)
+           and is_pkgname_in_whitelist(pkg.name, cache.whitelist)):
             try:
-                ver_in_allowed_origin(pkg, allowed_origins)
+                ver_in_allowed_origin(pkg, cache.allowed_origins)
             except NoAllowedOriginError:
                 continue
-
             try_to_upgrade(pkg,
                            pkgs_to_upgrade,
-                           pkgs_kept_back,
-                           cache,
-                           allowed_origins,
-                           blacklist,
-                           whitelist)
+                           cache)
 
     if cache.get_changes():
         cache.clear()
 
-    return pkgs_to_upgrade, pkgs_kept_back
+    return pkgs_to_upgrade
 
 
 def get_dpkg_log_content(logfile_dpkg, install_start_time):
@@ -1489,15 +1797,19 @@
             if pkg.is_auto_removable}
 
 
-def is_autoremove_valid(cache, pkgname, auto_removable, blacklist, whitelist):
-    # type: (apt.Cache, str, AbstractSet[str], List[str], List[str]) -> bool
+def is_autoremove_valid(cache,           # type: UnattendedUpgradesCache
+                        pkgname,         # type: str
+                        auto_removable,  # type: AbstractSet[str]
+                        ):
+    # type: (...) -> bool
     changes = cache.get_changes()
     if not changes:
         # package is already removed
         return True
     pkgnames = {pkg.name for pkg in changes}
     for pkg in changes:
-        if not is_pkg_change_allowed(pkg, blacklist, whitelist):
+        if not is_pkg_change_allowed(pkg, cache.blacklist, cache.whitelist,
+                                     cache.strict_whitelist):
             logging.warning(
                 _("Keeping the following auto-removable package(s) because "
                   "they include %s which is set to be kept unmodified: %s"),
@@ -1526,15 +1838,19 @@
                   "they include %s which package is related to the running "
                   "kernel: %s"), packagename, " ".join(sorted(pkgnames)))
             return False
+    if cache.install_count > 0:
+        logging.error(
+            "The following packages are marked for installation or upgrade "
+            "which is not allowed when performing autoremovals: %s",
+            " ".join([pkg.name for pkg in changes if not pkg.marked_delete]))
+        return False
     return True
 
 
-def do_auto_remove(cache,             # type: apt.Cache
+def do_auto_remove(cache,             # type: UnattendedUpgradesCache
                    auto_removable,    # type: AbstractSet[str]
                    logfile_dpkg,      # type: str
                    minimal_steps,     # type: bool
-                   blacklist,         # type: List[str]
-                   whitelist,         # type: List[str]
                    verbose=False,     # type: bool
                    dry_run=False      # type: bool
                    ):
@@ -1554,8 +1870,7 @@
             if pkgname in pkgs_removed:
                 continue
             cache[pkgname].mark_delete()
-            if not is_autoremove_valid(cache, pkgname, auto_removable,
-                                       blacklist, whitelist):
+            if not is_autoremove_valid(cache, pkgname, auto_removable):
                 # this situation can occur when removing newly unused packages
                 # would also remove old unused packages which are not set
                 # for removal, thus getting there is not handled as an error
@@ -1574,8 +1889,7 @@
     else:
         for pkgname in auto_removable:
             cache[pkgname].mark_delete()
-        if is_autoremove_valid(cache, "", auto_removable, blacklist,
-                               whitelist):
+        if is_autoremove_valid(cache, "", auto_removable):
             # do it in one step
             if not dry_run:
                 res, error = cache_commit(cache, logfile_dpkg, verbose)
@@ -1635,10 +1949,27 @@
     return False
 
 
-def main(options, rootdir=""):
+def update_kept_pkgs_file(kept_pkgs, kept_file):
+    # type: (DefaultDict[str, List[str]], str) -> None
+    if kept_pkgs:
+        pkgs_all_origins = set()
+        for origin_pkgs in kept_pkgs.values():
+            pkgs_all_origins.update(origin_pkgs)
+        try:
+            with open(kept_file, "w") as kf:
+                kf.write(" ".join(sorted(pkgs_all_origins)))
+        except FileNotFoundError:
+            logging.error(_("Could not open %s for saving list of packages "
+                            "kept back." % kept_file))
+    else:
+        if os.path.exists(kept_file):
+            os.remove(kept_file)
+
+
+def main(options, rootdir="/"):
     # type: (Options, str) -> int
     # useful for testing
-    if rootdir:
+    if not rootdir == "/":
         _setup_alternative_rootdir(rootdir)
 
     # see debian #776752
@@ -1661,6 +1992,12 @@
     try:
         res = run(options, rootdir, mem_log, logfile_dpkg,
                   install_start_time)
+
+        if res.success and res.result_str:
+            # complete, successful run
+            update_kept_pkgs_file(res.pkgs_kept_back,
+                                  os.path.join(rootdir, KEPT_PACKAGES_FILE))
+
         if res.result_str and not options.dry_run:
             # there is some meaningful result which is worth an email
             log_content = get_dpkg_log_content(logfile_dpkg,
@@ -1687,17 +2024,21 @@
         log_content = get_dpkg_log_content(logfile_dpkg,
                                            install_start_time)
         if not options.dry_run:
-            send_summary_mail(["<unknown>"], False, _("An error occurred"), [],
-                              [], [],
-                              mem_log, log_content)
+            send_summary_mail(["<unknown>"], False, _("An error occurred"),
+                              None, [], [], mem_log, log_content)
         # Re-raise exceptions for apport
         raise
 
 
 def mark_pkgs_to_upgrade(cache, pkgs_to_upgrade):
-    # type (apt.Cache, List[apt.Package]) -> None
-    for pkg in pkgs_to_upgrade:
-        if pkg.is_upgradable:
+    # type (apt.Cache, List[str]) -> None
+    for pkg_name in pkgs_to_upgrade:
+        pkg = cache[pkg_name]
+        if pkg.is_upgradable \
+           or (pkg.is_installed
+               and pkg.candidate.version != pkg.installed.version) \
+            and apt_pkg.config.find_b("Unattended-Upgrade::Allow-downgrade",
+                                      False):
             cache.mark_upgrade_adjusted(pkg,
                                         from_user=not pkg.is_auto_installed)
         elif not pkg.is_installed:
@@ -1754,24 +2095,9 @@
         syslog.syslog(_("Not running on the development release."))
         logging.info(_("Not running on the development release."))
         return UnattendedUpgradesResult(True)
-    # format (origin, archive), e.g. ("Ubuntu","dapper-security")
-    allowed_origins = get_allowed_origins()
-
-    # pkgs that are (for some reason) not safe to install
-    blacklist = get_blacklist()
-    logging.info(_("Initial blacklist : %s"),
-                 " ".join(blacklist))
-
-    # install only these packages regardless of other upgrades available
-    whitelist = get_whitelist()
-    logging.info(_("Initial whitelist: %s"),
-                 " ".join(whitelist))
 
     logging.info(_("Starting unattended upgrades script"))
 
-    # display available origin
-    logging.info(_("Allowed origins are: %s"), ", ".join(allowed_origins))
-
     # check and get lock
     try:
         apt_pkg.pkgsystem_lock()
@@ -1805,8 +2131,7 @@
 
     # get a cache
     try:
-        cache = UnattendedUpgradesCache(rootdir=rootdir,
-                                        allowed_origins=allowed_origins)
+        cache = UnattendedUpgradesCache(rootdir=rootdir)
     except SystemError as error:
         print(_("Apt returned an error, exiting"))
         print(_("error message: %s") % error)
@@ -1837,8 +2162,7 @@
     auto_removable = get_auto_removable(cache)
 
     # find out about the packages that are upgradable (in an allowed_origin)
-    pkgs_to_upgrade, pkgs_kept_back = calculate_upgradable_pkgs(
-        cache, options, allowed_origins, blacklist, whitelist)
+    pkgs_to_upgrade = calculate_upgradable_pkgs(cache, options)
     pkgs_to_upgrade.sort(key=lambda p: p.name)
     pkgs = [pkg.name for pkg in pkgs_to_upgrade]
     logging.debug("pkgs that look like they should be upgraded: %s"
@@ -1849,7 +2173,7 @@
     os.nice(old_priority - os.nice(0))
 
     # download what looks good
-    mark_pkgs_to_upgrade(cache, pkgs_to_upgrade)
+    mark_pkgs_to_upgrade(cache, pkgs)
 
     if options.debug:
         fetcher = apt_pkg.Acquire(apt.progress.text.AcquireProgress())
@@ -1874,16 +2198,17 @@
     except SystemError as e:
         logging.error("fetch.run() result: %s", e)
 
-    if cache.get_changes():
-        cache.clear()
-
     if options.download_only:
         return UnattendedUpgradesResult(True)
 
+    if cache.get_changes():
+        cache.clear()
+
     pkg_conffile_prompt = False
     if dpkg_conffile_prompt():
         # now check the downloaded debs for conffile conflicts and build
         # a blacklist
+        conffile_blacklist = []  # type: List[str]
         for item in fetcher.items:
             logging.debug("%s" % item)
             if item.status == item.STAT_ERROR:
@@ -1909,8 +2234,8 @@
                     "APT::Get::AllowUnauthenticated", False):
                 logging.debug("%s is blacklisted because it is not trusted")
                 pkg_name = pkgname_from_deb(item.destfile)
-                if not is_pkgname_in_blacklist(pkg_name, blacklist):
-                    blacklist.append("%s$" % re.escape(pkg_name))
+                if not is_pkgname_in_blacklist(pkg_name, cache.blacklist):
+                    conffile_blacklist.append("%s$" % re.escape(pkg_name))
             if not is_deb(item.destfile):
                 logging.debug("%s is not a .deb file" % item)
                 continue
@@ -1931,18 +2256,20 @@
                                   "needs to be upgraded manually"),
                                 pkgname_from_deb(item.destfile))
                 pkg_name = pkgname_from_deb(item.destfile)
-                if not is_pkgname_in_blacklist(pkg_name, blacklist):
-                    blacklist.append("%s$" % re.escape(pkg_name))
-                pkgs_kept_back.append(pkgname_from_deb(pkg_name))
+                if not is_pkgname_in_blacklist(pkg_name, cache.blacklist):
+                    conffile_blacklist.append("%s$" % re.escape(pkg_name))
                 pkg_conffile_prompt = True
 
         # redo the selection about the packages to upgrade based on the new
         # blacklist
-        logging.debug("blacklist: %s" % blacklist)
-        # whitelist
-        logging.debug("whitelist: %s" % whitelist)
+        logging.debug("Packages blacklist due to conffile prompts: %s"
+                      % conffile_blacklist)
         # find out about the packages that are upgradable (in a allowed_origin)
-        if len(blacklist) > 0 or len(whitelist) > 0:
+        if len(conffile_blacklist) > 0:
+            for regex in conffile_blacklist:
+                cache.blacklist.append(regex)
+            cache.apply_pinning(cache.pinning_from_regex_list(
+                conffile_blacklist, NEVER_PIN))  # type: ignore
             old_pkgs_to_upgrade = pkgs_to_upgrade[:]
             pkgs_to_upgrade = []
             for pkg in old_pkgs_to_upgrade:
@@ -1950,14 +2277,9 @@
                               (pkg.name))
                 cache.mark_upgrade_adjusted(
                     pkg, from_user=not pkg.is_auto_installed)
-                if check_changes_for_sanity(cache,
-                                            allowed_origins,
-                                            blacklist,
-                                            whitelist):
+                if check_changes_for_sanity(cache):
                     pkgs_to_upgrade.append(pkg)
                 else:
-                    if not (pkg.name in pkgs_kept_back):
-                        pkgs_kept_back.append(pkg.name)
                     logging.info(_("package %s not upgraded"), pkg.name)
                     cache.clear()
                     for pkg2 in pkgs_to_upgrade:
@@ -1994,7 +2316,7 @@
              kernel_pkgs_removed,
              kernel_pkgs_kept_installed) = do_auto_remove(
                 cache, auto_removable_kernel_pkgs, logfile_dpkg,
-                options.minimal_upgrade_steps, blacklist, whitelist,
+                options.minimal_upgrade_steps,
                 options.verbose or options.debug, options.dry_run)
             auto_removable = get_auto_removable(cache)
 
@@ -2007,15 +2329,17 @@
 
     # exit if there is nothing to do and nothing to report
     if (len(pending_autoremovals) == 0
-            and len(pkgs_to_upgrade) == 0
-            and len(pkgs_kept_back) == 0):
+            and len(pkgs_to_upgrade) == 0):
         logging.info(_("No packages found that can be upgraded unattended "
                        "and no pending auto-removals"))
+
+        pkgs_kept_back = cache.find_kept_packages(options.dry_run)
         return UnattendedUpgradesResult(
             kernel_pkgs_remove_success,
             _("No packages found that can be upgraded unattended and no "
               "pending auto-removals"),
             pkgs_removed=kernel_pkgs_removed,
+            pkgs_kept_back=pkgs_kept_back,
             pkgs_kept_installed=kernel_pkgs_kept_installed,
             update_stamp=True)
 
@@ -2043,9 +2367,7 @@
     if len(pkgs_to_upgrade) > 0:
         # do install
         pkg_install_success = do_install(cache,
-                                         pkgs_to_upgrade,
-                                         blacklist,
-                                         whitelist,
+                                         pkgs,
                                          options,
                                          logfile_dpkg)
     # Was the overall run succesful: only if everything installed
@@ -2060,6 +2382,10 @@
         return UnattendedUpgradesResult(
             False, _("Cache has broken packages, exiting"), pkgs=pkgs)
 
+    # make sure we start autoremovals with a clear cache
+    if cache.get_changes():
+        cache.clear()
+
     # the user wants *all* auto-removals to be removed
     # (unless u-u got signalled to stop gracefully quickly)
     pkgs_removed = []         # type: List[str]
@@ -2072,7 +2398,7 @@
          pkgs_removed,
          pkgs_kept_installed) = do_auto_remove(
             cache, auto_removals, logfile_dpkg, options.minimal_upgrade_steps,
-            blacklist, whitelist, options.verbose or options.debug,
+            options.verbose or options.debug,
             options.dry_run)
         successful_run = successful_run and pkg_remove_success
     # the user wants *only new* auto-removals to be removed
@@ -2085,7 +2411,7 @@
          pkgs_removed,
          pkgs_kept_installed) = do_auto_remove(
             cache, auto_removals, logfile_dpkg, options.minimal_upgrade_steps,
-            blacklist, whitelist, options.verbose or options.debug,
+            options.verbose or options.debug,
             options.dry_run)
         successful_run = successful_run and pkg_remove_success
 
@@ -2101,6 +2427,7 @@
             and pkg_install_success):
         clean_downloaded_packages(fetcher)
 
+    pkgs_kept_back = cache.find_kept_packages(options.dry_run)
     return UnattendedUpgradesResult(
         successful_run, _("All upgrades installed"), pkgs,
         pkgs_kept_back,
@@ -2164,8 +2491,8 @@
     parser.add_option("", "--no-minimal-upgrade-steps",
                       action="store_false", default=minimal_steps_default,
                       dest="minimal_upgrade_steps",
-                      help=_("Upgrade in minimal steps (and allow "
-                             "interrupting with SIGTERM"))
+                      help=_("Upgrade all packages together instead of in "
+                             "smaller sets"))
     parser.add_option("", "--minimal_upgrade_steps",
                       action="store_true",
                       help=SUPPRESS_HELP,
